{% load static %}
{% load pwa %}
<!DOCTYPE html>
<html>
  <head>
    {% progressive_web_app_meta %}
    <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
    <script src="https://cdn.rawgit.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js"></script>
  </head>
  <body style="margin: 0; overflow: hidden;">
    <a-scene embedded arjs vr-mode-ui="enabled: false">
        <a-marker type="pattern" url="{{model.marker.url}}">
            <a-entity 
                  id="model"
                  gltf-model="url({{model.threedfile.url}})"
                  scale="1 1 1" 
                  position="0 0 0" 
                  rotation="0 0 0"
                  data-description="{{model.description}}">
            </a-entity>
        </a-marker>
        <a-entity camera></a-entity>
    </a-scene>

    <!-- TTS Button -->
    <button id="ttsButton" style="
      position: absolute;
      bottom: 10px;
      left: 50%;
      transform: translateX(-50%);
      padding: 10px 20px;
      font-size: 16px;
      background-color: #4CAF50;
      color: white;
      border: none;
      border-radius: 5px;
      cursor: pointer;
    ">
      Speak Description
    </button>

    <script>
      // Text to Speech functionality
      const ttsButton = document.getElementById("ttsButton");
      const model = document.getElementById("model");

      ttsButton.addEventListener("click", () => {
        const description = model.getAttribute("data-description") || "No description available.";
        const synth = window.speechSynthesis;
        const utterance = new SpeechSynthesisUtterance(description);

        // Set voice attributes (optional)
        utterance.pitch = 1;   // Pitch of the voice
        utterance.rate = 1;    // Speed of the voice

        // Speak the description
        synth.speak(utterance);
      });

      // Model interaction logic
      let startX = null;
      let initialRotationY = 0;

      // Helper function to calculate the distance between two touch points (for pinch zoom)
      function getDistance(touch1, touch2) {
        const dx = touch1.clientX - touch2.clientX;
        const dy = touch1.clientY - touch2.clientY;
        return Math.sqrt(dx * dx + dy * dy);
      }

      // Event listener for touch start (detect horizontal swipe for rotation)
      window.addEventListener('touchstart', (event) => {
        if (event.touches.length === 1) {  // Detect one finger swipe for rotation
          startX = event.touches[0].clientX;
          const currentRotation = model.getAttribute('rotation');
          initialRotationY = currentRotation.y;
        }
        if (event.touches.length === 2) {  // Detect two-finger touch for resizing
          initialDistance = getDistance(event.touches[0], event.touches[1]);
          const currentScale = model.getAttribute('scale');
          initialScale = parseFloat(currentScale.x);  // Assume uniform scaling
        }
      });

      // Event listener for touch move (rotation for horizontal swipe, zoom for pinch)
      window.addEventListener('touchmove', (event) => {
        if (event.touches.length === 1 && startX !== null) {
          const currentX = event.touches[0].clientX;
          const deltaX = currentX - startX;

          // Update rotation only on Y-axis based on horizontal swipe
          const newRotationY = initialRotationY + deltaX * 0.5;  // Adjust sensitivity
          model.setAttribute('rotation', `0 ${newRotationY} 0`);
        }
        if (event.touches.length === 2 && initialDistance) {
          const currentDistance = getDistance(event.touches[0], event.touches[1]);
          const scaleChange = currentDistance / initialDistance;
          const newScale = initialScale * scaleChange;
          model.setAttribute('scale', `${newScale} ${newScale} ${newScale}`);
        }
      });

      // Reset on touch end
      window.addEventListener('touchend', () => {
        startX = null;
        initialDistance = null;  // Reset distance for scaling
      });
    </script>
  </body>
</html>
